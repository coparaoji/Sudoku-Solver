{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def showImage(img,title='Resized Window'):\n",
    "\n",
    "    #define the screen resulation\n",
    "    screen_res = 1280, 720\n",
    "    scale_width = screen_res[0] / img.shape[1]\n",
    "    scale_height = screen_res[1] / img.shape[0]\n",
    "    scale = min(scale_width, scale_height)\n",
    "\n",
    "    #resized window width and height\n",
    "    window_width = int(img.shape[1] * scale)\n",
    "    window_height = int(img.shape[0] * scale)\n",
    "\n",
    "    #cv.WINDOW_NORMAL makes the output window resizealbe\n",
    "    cv.namedWindow(title, cv.WINDOW_NORMAL)\n",
    "\n",
    "    #resize the window according to the screen resolution\n",
    "    cv.resizeWindow(title, window_width, window_height)\n",
    "\n",
    "    cv.imshow(title, img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "import random\n",
    "#function to get a random file\n",
    "def random_file(path):\n",
    "    if(os.path.isfile(path)):\n",
    "        return path\n",
    "    else:\n",
    "        x = os.listdir(path)\n",
    "        return random_file(os.path.join(path,x[random.randint(0, len(x)-1)]))\n",
    "\n",
    "#function to get random picture of specific number\n",
    "def get_rand_pic_of(number):\n",
    "    x = os.listdir(\"Dataset\")\n",
    "    y = x[random.randint(0, len(x)-1)]\n",
    "    x = os.path.join(\"Dataset\",y)\n",
    "    x = os.path.join(x,str(number))\n",
    "    return random_file(x)\n",
    "\n",
    "#methods\n",
    "#open image in opencv//done\n",
    "#apply thresholding to image and resize//done\n",
    "# and save the image in a new folder\n",
    "#return an array of all the images for a given number and purpose (test or train)\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def open_image(path):\n",
    "    x = cv.imread(path,0)\n",
    "    if (x is None):\n",
    "        raise Exception(\"File not found\")\n",
    "    return x\n",
    "\n",
    "def preprocess(image):\n",
    "    if(np.max(image)<100):\n",
    "        image = image*255\n",
    "    image =  cv.resize(image, (32,32), interpolation=cv.INTER_AREA)\n",
    "    image =  cv.adaptiveThreshold(image,255,cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,15,10)\n",
    "    image = image/255\n",
    "\n",
    "    return image\n",
    "\n",
    "def one_hot_encoder(num, num_classes = 9):\n",
    "    x = np.zeros(num_classes)\n",
    "    x[int(num)] = 1.0\n",
    "    return x\n",
    "\n",
    "\n",
    "class ImageRetriever:\n",
    "    id = \"\" #file name\n",
    "    label = \"\" #0-9\n",
    "    purpose = \"\" #training_data or testing_data\n",
    "    raw_image = None\n",
    "\n",
    "    def __init__(self, raw_image = None, path = \"\", purpose = \"\", id = \"\")-> None:\n",
    "        self.raw_image = raw_image\n",
    "        self.path = path\n",
    "        self.purpose = purpose\n",
    "        self.id = id\n",
    "\n",
    "    \n",
    "\n",
    "    def get(self, path):\n",
    "        self.raw_image = preprocess(open_image(path))\n",
    "        self.id = path.split('/')[-1].split('.')[0]\n",
    "        self.label = path.split('/')[-2]\n",
    "        self.label = to_categorical(int(self.label)-1, num_classes=9)\n",
    "        self.purpose = path.split('/')[1]\n",
    "\n",
    "def get_data_split(file=\"training_data\", image_retriever = ImageRetriever()):\n",
    "    path = os.path.join(\"Dataset\",file)\n",
    "    train = np.ndarray((0,32,32,1))\n",
    "    labels = np.ndarray((0,10))\n",
    "    for number_folder in os.listdir(path):\n",
    "        for number_image in os.listdir(os.path.join(path,number_folder)):\n",
    "            image_path = os.path.join(path,number_folder,number_image)\n",
    "            image_retriever.get(image_path)\n",
    "            train = np.vstack([train,image_retriever.raw_image.reshape((1,32,32,1))])\n",
    "            labels = np.vstack([labels, image_retriever.label.reshape((1,10))])\n",
    "    return train, labels\n",
    "\n",
    "def build_model():\n",
    "    num_classes = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3,3),\n",
    "                    activation='relu',\n",
    "                    input_shape=(28,28,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_and_train_model():\n",
    "    model = build_model()\n",
    "    train,labels = get_data_split()\n",
    "    model.fit(train,labels, epochs = 5)\n",
    "\n",
    "    test, test_labels = get_data_split(file = \"testing_data\")\n",
    "\n",
    "    print(model.evaluate(test,test_labels))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ImageRetriever('Dataset/training_data/4/44516.png')\n",
    "y = x.get('Dataset/training_data/4/44516.png')\n",
    "\n",
    "\n",
    "#showImage(x.raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is Dataset/training_data/7/50387.png\n"
     ]
    }
   ],
   "source": [
    "y = random_file(\"Dataset\")\n",
    "x.get(y)\n",
    "\n",
    "#showImage(x.raw_image)\n",
    "print(f\"file is {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.raw_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage(x.raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = cv.bitwise_not(X_train)\n",
    "X_test = cv.bitwise_not(X_test)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_train = tf.image.resize(X_train, [32,32], method='nearest')\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "X_test = tf.image.resize(X_test, [32,32], method='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_train = tf.image.resize(X_train, [32,32], method='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage(np.array(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154,\n",
       "         253,  90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  60, 179,\n",
       "         253, 112,   3,  19,  30,   5,   0,   0,  63,  61,  13,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  21,  63,  56,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0, 189, 223, 250, 104,  18,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 102, 190, 190, 190, 159, 101,  99,  12,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 179, 228,\n",
       "         252, 157,   9,  56,  91,  16,   0,   0, 190, 182,  38,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  64, 189, 167,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,  68, 162, 251, 185,  53,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  34,  63,  63,  63,  53,  34,  33,   4,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252,\n",
       "         252, 179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.resize(x,(4,4),cv.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter = np.where((Y_train != 0 ))\n",
    "test_filter = np.where((Y_test != 0))\n",
    "X_train, Y_train = X_train[train_filter], Y_train[train_filter]\n",
    "X_test, Y_test = X_test[test_filter], Y_test[test_filter]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 42396368 into shape (54077,32,32,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-421969f366bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 42396368 into shape (54077,32,32,1)"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 32, 32, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 32, 32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode target values\n",
    "Y_train = to_categorical(Y_train-1,num_classes=9)\n",
    "Y_test = to_categorical(Y_test-1,num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test = prep_pixels(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 32, 32, 1), found shape=(None, 28, 28, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-bf9f274593b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/alex/.local/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 32, 32, 1), found shape=(None, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,batch_size=32,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    num_classes = 9\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                    activation='relu',\n",
    "                    input_shape=(32,32,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2)))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2)))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_and_train_model():\n",
    "    model = build_model()\n",
    "    train,labels = get_data_split()\n",
    "    model.fit(train,labels, epochs = 5)\n",
    "\n",
    "    test, test_labels = get_data_split(file = \"testing_data\")\n",
    "\n",
    "    print(model.evaluate(test,test_labels))\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.ndarray((0,32,32,1))\n",
    "labels = np.ndarray((0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = np.vstack([train, x.raw_image.reshape((1,32,32,1))])\n",
    "labels = np.vstack([labels, x.label.reshape((1,10))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.get(get_rand_pic_of(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.vstack([train,x.raw_image.reshape((1,32,32,1))])\n",
    "labels = np.vstack([labels, x.label.reshape((1,10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 1)\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.raw_image.shape\n",
    "x.label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 2.2975 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3eb4f20f10>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_split(file=\"training_data\", image_retriever = ImageRetriever()):\n",
    "    path = os.path.join(\"Dataset\",file)\n",
    "    train = np.ndarray((0,32,32,1))\n",
    "    labels = np.ndarray((0,9))\n",
    "    for number_folder in os.listdir(path):\n",
    "        for number_image in os.listdir(os.path.join(path,number_folder)):\n",
    "            image_path = os.path.join(path,number_folder,number_image)\n",
    "            image_retriever.get(image_path)\n",
    "            train = np.vstack([train,image_retriever.raw_image.reshape((1,32,32,1))])\n",
    "            labels = np.vstack([labels, image_retriever.label.reshape((1,9))])\n",
    "    return train, labels\n",
    "            \n",
    "    \n",
    "\n",
    "train,labels = get_data_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "180/180 [==============================] - 3s 14ms/step - loss: 0.4551 - accuracy: 0.8649\n",
      "Epoch 2/5\n",
      "180/180 [==============================] - 3s 14ms/step - loss: 0.0511 - accuracy: 0.9866\n",
      "Epoch 3/5\n",
      "180/180 [==============================] - 3s 14ms/step - loss: 0.0277 - accuracy: 0.9920\n",
      "Epoch 4/5\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0140 - accuracy: 0.9958\n",
      "Epoch 5/5\n",
      "180/180 [==============================] - 3s 14ms/step - loss: 0.0107 - accuracy: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3eb536f9a0>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train,labels, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 12, 12, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 6, 6, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,794\n",
      "Trainable params: 44,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, test_labels = get_data_split(file = \"testing_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 4ms/step - loss: 3.8148e-04 - accuracy: 1.0000\n",
      "[0.000381484191166237, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(test,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.get(get_rand_pic_of(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = x.raw_image\n",
    "model.predict(image.reshape((1,32,32,1)))\n",
    "results = model.predict(image.reshape((1,32,32,1)))\n",
    "results = np.argmax(results,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
